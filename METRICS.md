# Метрики качества
Оценка ответов участников производится по двум метрикам: генеративной и некоторой скрытой метрике.

Метрику оценки генерации ответов модели предлагается рассчитывать с применением **METEOR**, которая умножается на весовой коэффициент,
в зависимости от типа диалога, к которому относится реплика.

**Скрытая метрика** основывается на внутренней оценке уверенности модели в ответе. 
Участникам предлагается, в рамках вычисления данной метрики, предоставлять численное значение 
перплексии модели в ответ на входные данные. В дальнейшем, показатель перплексии будет использоваться в расчете скрытой метрики.

Финальный результат участника и распределение мест будет оцениваться в соответствии с **интегральной метрикой**. <br>

### Генеративная метрика
Метрику оценки генерации ответов модели предлагается рассчитывать с применением **METEOR**.

**METEOR** – метрика, основанная на анализе n-грамм и ориентированная на использование статистической и точной оценки исходного текста. 
Данная метрика использует функции сопоставления синонимов вместе с точным соответствием слов. 

Алгоритм сначала проводит выравнивание текста между двумя предложениями – строкой эталонного перевода и строкой входного текста для оценивания. Затем используется несколько этапов установления соответствия между словами машинного перевода и эталонного перевода для сопоставления двух строк:
1. Точное установление соответствия — определяются строки, которые являются идентичными в эталонном и машинном переводе.
2. Установление соответствия основ — проводится стемминг (выделение основы слова), и определяются слова с одинаковым корнем в эталонном и машинном переводе.
3. Установление соответствия синонимов — определяются слова, которые являются синонимами в соответствии с RuWordNet.

Выравнивание — это множество соответствий между n-граммами. На соответствие налагается следующее ограничение: каждый n-грамм в предложении-кандидате должен соответствовать одному или ни одному n-грамму в эталонном предложении. Если есть два выравнивания с тем же количеством совпадений, то выбирается то, которое имеет наименьшее количество пересечений для совпадений. Этапы сравнения с эталонными переводами выполняются последовательно, и на каждом из них ко множеству соответствий добавляются только те n-граммы, которые не имели соответствия на предыдущих этапах. Как только будет пройден последний этап, окончательное значение точности (precision) n-грамм вычисляется по следующей формуле:

$$\text{P}=\frac{m}{w_t},$$

где $m$ - количество n-грамм в машинном переводе, которые также были найдены в эталонном переводе, $w_t$ — количество n-грамм в машинном переводе. 

Значение полноты (recall) n-грамм (общий n-грамм для эталонных переводов) вычисляется по следующей формуле:

$$\text{R}=\frac{m}{w_r},$$

где $w_r$ — количество n-грамм в эталонном переводе.

В результате METEOR рассчитывается как комбинация точности и полноты, используя формулу гармонического среднего, 
в которой вес полноты в 9 раз больше веса точности:

$$\text{METEOR}=\frac{10PR}{R&plus;9P}.$$

При расчете метрики каждый ответ участника будет сравниваться с несколькими вариациями правильного ответа 
(например, короткий и длинный формат одного и того же ответа), 
в качестве финального значения метрики **METEOR** для текущей реплики будет выбрана тот вариант, 
который показал максимальное значение из всех возможных.


### Скрытая метрика

**Hidden metric (HM)** — скрытая метрика для оценки качества решения задачи. Она основывается на **внутренней оценке уверенности модели в ответе**. 
Участникам предлагается, в рамках вычисления данной метрики, предоставлять численное значение **перплексии модели** в ответ на входные данные. 
В дальнейшем, показатель перплексии будет использоваться в расчете скрытой метрики.

**Перплексия** в языковой модели — определяется как эскпонента от усредненной функции отрицательного правдоподобия (negative log-likelihood) последовательности токенов.
Таким образом, если мы имеем некоторую токенизированную последовательность $X=(x_0,x_1,…,x_t)$, тогда значение перплексии для последовательности $X$ вычисляется как:


$$PPL(X)=exp(\frac{1}{t}\sum_{i}^{t}\log{p_{\theta}(x_i|x_{\lt i})}),$$


где $\log{p_{\theta}(x_i|x_{\lt i})}$ — это правдоподобие $i$-ого токена при условии всех $x \lt i$ токенов, в соответствии с предсказаниями модели.

Кроме того, показатель перплексии - это ни что иное как экспонента кросс-энтропийного критерия качества между предсказаниями модели и целевыми ответами.

Скрытая метрика будет вычисляться по файлу ppl_output.json и принимать значения от 0 до 1, где 0 – наихудшее значение, 1 – наилучшее.

### Интегральная метрика


Метрики вычисляются по каждому типу диалогов и агрегируются с соответствующими весовыми коэффициентами в зависимости от типа диалога.


Таким образом, интегральная метрика вычисляется по следующей формуле:


$$\sum_{j=1}^J \frac{w_j}{N_j} \sum_{i=1}^{N_j} \frac{METEOR_i+HM_i}{2},$$


где $j$ — тип диалога ($J = ${Text2Text, Image2Text, Audio2Text, Image-Audio2Text}),


$N_j$ — количество диалогов $j$-го типа;


$METOR_i$ и $HM_i$ — усредненные значения метрики **METEOR** и скрытой метрики, вычисленные для всех реплик $i$-го диалога;


$w_j$ — вес для примеров диалога $j$-го типа.


* $w_j$ = 0.1 для диалогов типа **Text2Text**;
* $w_j$ = 0.2 для диалогов типа **Image2Text**;
* $w_j$ = 0.3 для диалогов типа **Audio2Text**;
* $w_j$ = 0.4 для диалогов типа **Image-Audio2Text**.








