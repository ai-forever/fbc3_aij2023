# The Survey of SoTA Multimodal Architectures (2023).

За последний год мы стали свидетелями стремительного развития больших языковых моделей 
(Large Language Models, LLMs), которые продемонстрировали уникальные интеллектуальные способности такие как: 
понимание, логическое рассуждение и обучение новым навыкам, аналогично тому, как сами люди получают 
и анализируют знания, рассуждают и принимают решения.

Обладая высоким уровнем интеллекта и возможностью интерактивно взаимодействовать с человеком, 
языковые модели позволяют создавать универсальные диалоговые системы, выполняющие инструкции пользователя. 

Однако задачи, которые ставит перед диалоговой системой человек не всегда заключаются только в естественном языке. 
Для того, чтобы раскрыть потенциальные возможности применения LLM за пределами одного лишь естественного языка, 
в ряде исследований, опубликованных в последние годы, были предприняты успешные попытки наладить взаимодействие 
языковых моделей с множеством разнообразных сигналов других модальностей (например, изображениями, видео, речью и аудио).
Таким образом, были предприняты попытки построения куда более умных и разноплановых диалоговых систем.

Поэтому, в качестве идейного вдохновения для создания модели умного мультимодального Ассистента мы предлагаем 
участникам ознакомиться с собранной нами подборкой SOTA мультимодальных архитектур 
на основе больших языковых моделей (Multimodal Large Language Models, MLLMs) за последний 2023 год.
С более ранними обзорами за 2021 и 2022 годы можно ознакомиться по ссылкам: Survey MLLM 2021 и Survey MLLM 2022.


## Surveys

Для начала мы предлагаем участникам самостоятельно ознакомиться с комплексными и наиболее полными обзорами текущего 
“ландшафта” разработки мультимодальных архитектур, которые были опубликованы за последние годы:

1. [Foundations and Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions](https://arxiv.org/abs/2209.03430) (```Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency, Sep. 2022```) — эта статья предлагает верхнеуровневый обзор теоретических и практических основ мультимодальных языковых моделей через определение трех основополагающих аспектов объединения модальностей: гетерогенности (heterogeneity), связанности (connections) и взаимосвязи (interactions). Также предлагается таксономия из шести основных задач: представление данных (representation), согласованность между представлениями модальностей (alignment), рассуждение (reasoning), генерация (generation), способности к генерализации на новые задачи (transference) и масштабируемость модели на новые модальности (quantification), охватывающую исторические и последние тенденции.
2. [A Survey on Multimodal Large Language Models](https://arxiv.org/abs/2306.13549) (```Yin et. al., June 2023```) — в этой статье подробно описываются последние достижения в области MLLM (Multimodal Large Language Models) в разрезе четырех основных техник реализации подобных архитектур: Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning (M-ICL), Multimodal Chain of Thought (M-CoT), и LLM-Aided Visual Reasoning (LAVR). К каждому из описанных направлений собрана детальная таксономия с примерами реализа
3. [Multimodal Learning with Transformers: A Survey](https://arxiv.org/abs/2206.06488) (```Peng Xu, Xiatian Zhu, David A. Clifton, May 2023```) — эта статья предоставляет читателю полноценный обзор применения трансформерных моделей к мультимодальным данным. Она включает как основополагающее описание разнообразных трансформерных архитектур (от Vanilla Transformer и Vision Transformer  до более комплексных мультимодальных Transformers) и методов их предобучения, так и перечень возможных практических задач в рамках применения мультимодальных моделей.
4. [Multi-modal Machine Learning in Engineering Design: A Review and Future Directions](https://arxiv.org/abs/2302.10909) (```Binyang Song, Rui Zhou, Faez Ahmed, Feb. 2023```) — в данной статье подробно исследуются наиболее современные задачи применения мультимодальных моделей машинного обучения (Multimodal Models of Machine Learning, MMML) в разрезе пяти фундаментальных задач мультимодального обучения: мультимодальное представление данных (multi-modal information representation), объединение различных источников данных (fusion), согласованность между представлениями модальностей (alignment), перенос информации в рамках модальностей (translation), и объединенное обучение моделей на нескольких источниках сигналов разной природы (co-learning).

## SoTA Мультимодальные архитектуры

Далее, приводится краткий обзор основных опубликованных работ по теме мультимодальности (за период 2023 года), которые либо показали выдающееся качество решений по ряду задач и модальностей, либо привнесли в это поле исследований новые принципы построения архитектуры моделей.
