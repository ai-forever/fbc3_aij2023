## Baseline решение

За основу предлагается взять подходы [FROMAGe](https://github.com/kohjingyu/fromage) и [Kosmos-1](https://github.com/microsoft/unilm/tree/master/kosmos-2) для файнтюнинга линейного отображения из векторного пространства визуальной и аудио  модальностей в векторное пространство языковой модели-декодера и дальнейшей генерации ответа только с помощью языковой модели. В качестве энкодера дополнительных модальностей берётся CLIP-подобный энкодер [ImageBind](https://github.com/facebookresearch/ImageBind), обученный для задачи понимания  изображений, аудио и текста.

Веса энкодера и языковой модели в процессе обучения заморожены, за исключением дополнительных эмбеддингов для двух токенов начала и конца соответствующей модальности в языковой модели **\<SOM\>**, **\<EOM\>**.

Для обучения возможно использовать произвольные инструктивные и описательные датасеты, такие как аудиозаписи с субтитрами или вопросы по картинкам. В ходе обучения решается базовая задача предсказания следующего токена c архитектурой, описанной на схеме:

<p align="center">
<img alt="Baseline model architecture" src="../assets/baseline.png" width="100%">
</p>

1. Данные $y$ модальностей, кроме текстовой, переводятся в промежуточный эмбеддинг предобученным энкодером в эмбеддинг $v_\phi(y) \in \mathbb{R}^{m}$;
2. Линейным отображением $v^\top_\phi(y)\mathbf{W}, \mathbf{W} \in \mathbb{R}^{m \times kd}$ эмбеддинг переводится в $k$ векторов пространства языковой модели размерности $d$;
3. Токены, сигнализирующие о начале и конце данных соответствующей модальности, также имеют обучаемые эмбеддинги размерности $d$. В явном виде добавлять их в словарь модели не требуется.

## Запуск обучения
Чтобы воспроизвести бейзлайн, после установки зависимостей 
```
pip install requirements.txt
```
нужно запустить все ячейки в [ноутбуке](./baseline.ipynb).